# Lesson: Advanced Interaction Technologies & Applications

### First and Last Name: Chronas Aggelos
### University Registration Number: dpsd18136
### GitHub Personal Profile: https://github.com/AggelosXrn
### Advanced Interaction Tecnologies & Applications Github Personal Repository: https://github.com/merkourisa/Advanced-Interaction-Tecnologies-Applications-Individual-Assignment


# 1st Deliverable
![image](https://user-images.githubusercontent.com/93786079/200710311-727681dc-5659-4384-afec-7c87f87eecea.png)

Προηγμένες Τεχνολογίες Αλληλεπίδρασης και Εφαρμογές
Ονοματεπώνυμο: Χρονάς Άγγελος
ΑΜ: Dpsd18136
GitHub Profile: AggelosXrn/ https://github.com/AggelosXrn

URL Εργασίας στο GitHub: https://github.com/AggelosXrn/Advanced-Interaction-Tecnologies-Applications-Individual-Assignment/tree/main/source_code/1st_Deliverable

1ο Παραδοτέο :

Στο πρώτο υποερώτημα με τη χρήση του κατάλληλου κώδικα σύνδεσα το Prossessing με την κάμερα ώστε αυτή να καταγράφει βίντεο. Αυτό έγινε με τη χρήση του παραδείγματος 16.1 από το  Learning Processing, 2nd Edition. Για να τρέξει σωστά το πρόγραμμα χρειάστηκε να κατεβάσω και ν εγκαταστήσω στην νεότερη έκδοση τη βιβλιοθήκη gstreamer. 
 ![image](https://user-images.githubusercontent.com/93786079/200710352-879ea576-5bba-44b6-990e-e360e069629a.png)

2ο Παραδοτέο:

Στο δεύτερο παραδοτέο μας ζητήθηκε να εισάγουμε ένα μικρό δικό μας βίντεο διάρκειας περίπου 10 δευτερολέπτων να παίζει σε επανάληψη. Έπειτα θα έπρεπε να δίνεται στον χρήστη η δυνατότητα να χειρίζεται την ταχύτητα που τρέχει το βίντεο αναλόγως με τη θέση του ποντικιού του. Πρώτο βήμα για την υλοποίηση του παραδοτέου ήταν η μελέτη των παραδειγμάτων  16-4 και  16-5 από το βιβλίο Learning Processing, 2nd Edition. Φαίνεται επίσης πάνω αριστερά στο παράθυρο η ταχύτητα με την οποία τρέχει εκείνη τη στιγμή το βίντεο. 
    ![image](https://user-images.githubusercontent.com/93786079/200710401-1b328566-d047-43d3-bf67-b923efde3f79.png)
![image](https://user-images.githubusercontent.com/93786079/200710457-11f81ccc-98a6-4447-8f7d-447343008b43.png)
![image](https://user-images.githubusercontent.com/93786079/200710515-2f55dba5-b19b-41f7-b616-9d9807aba243.png)
![image](https://user-images.githubusercontent.com/93786079/200710594-e59aaf35-b94a-4c31-8cbf-2eae3c4f82fd.png)

3ο Παραδοτέο:

Πρώτο βήμα στο 3ο παραδοτέο ήταν η εισαγωγή της βιβλιοθήκης QRCode library στο Processing. Έπειτα έφτιαξα το QRCode μου με το URL να δείχνει προσωπικό μου Github λογαριασμό. Στη συνέχεια με το κατάλληλο πρόγραμμα και με βάση το έτοιμο παράδειγμα της βιβλιοθήκης, έκανα να εμφανίζει την εικόνα με το QRCode μου. ‘Οταν αναγνωρίζεται το QRCode ανοίγει το URL που είναι αποθηκευμένο σε αυτό σε μια νέα ιστοσελίδα.
 ![image](https://user-images.githubusercontent.com/93786079/200710612-df473f62-0053-4edd-b66c-0093194592a6.png)

4ο Παραδοτέο:

Στο 4ο παραδοτέο προσάρμοσα κατάλληλα το έτοιμο παράδειγμα της βιβλιοθήκης QR Example ώστε όταν η κάμερα διαβάζει το QRCode μου να ανοίγει το URL που είναι αποθηκευμένο σε αυτό σε μια νέα ιστοσελίδα. Αρχικά αντικατέστησα το loadImage με τη δική μου εικόνα, το QRCode μου και επίσης πρόσθεσα μία γραμμή κώδικα για το link του λογαριασμού μου στο GitHub.
5ο Παραδοτέο:

Το πρώτο βήμα που ακολούθησα για την υλοποίηση του 5ου Παραδοτέου ήταν να ανατρέξω στις οδηγίες που μας δίνονται από το  My first AR exploration with Processing. Έπειτα κατέβασα και εγκατέστησα στο Processing τη βιβλιοθήκη NyARToolkit. Μέσω του έτοιμου παραδείγματος simpleLite κατάφερα με την αναγνώριση από την κάμερα του marker Hiro να εμφανίζεται πάνω σε αυτό στην κάμερα του υπολογιστή η παρακάτω εικόνα με μία μπάλα μπασκετ.
  ![image](https://user-images.githubusercontent.com/93786079/200710672-afac6bc5-7a67-4bcb-a40b-e488cecca01f.png)

# 2nd Derivable 

1ο Υποερώτημα:

Έπειτα από μελέτη και επεξεργασία του  Example 16-12 από το βιβλίο Learning Processing, 2nd Edition έκανα αφαίρεση του υπόβαθρου και αντικατάστασή του από μια εικόνα της επιλογής μου. Αυτό έγινε με 2 μικρές προσθήκες στον κώδικά μου οι οποίες ήταν:

1.	Να τοποθετήσω την δική μου εικόνα στο background 
2.	Να κάνω την κάμερα να κάνει Capture Video και να μην παίζει το έτοιμο βίντεο από το παράδειγμα
3.	Όπου κλικάρει ο χρήστης με το ποντίκι αναλόγως αφαιρείται και το background
  
  ![image](https://user-images.githubusercontent.com/93786079/207907165-9715b4a7-c0b7-43a6-be2b-550bc320dfe4.png)

![image](https://user-images.githubusercontent.com/93786079/207907189-cad5c395-0846-4ec6-a3c7-ce0f903a86f9.png)

![image](https://user-images.githubusercontent.com/93786079/207907224-d323b342-d139-41a3-87a2-dbebc50d815c.png)

![image](https://user-images.githubusercontent.com/93786079/207907239-3e8c4996-008b-4ad6-b367-3bc1a4dd9e5d.png)

   
2ο Υποερώτημα:
Στο δεύτερο υποερώτημα μας ζητήθηκε να πραγματοποιηθεί ο εντοπισμός κίνησης με μια. Με τη βοήθεια του παραδείγματος Example 16-11 και  Example 16-13 , Learning Processing, 2nd Edition έφτιαξα μία έλλειψη που ακολουθεί ένα κινούμενο αντικείμενο. Το αντικείμενο αυτό είναι το χέρι του χρήστη. Παρόλο που αρχικά εντόπιζε και την κίνηση του σώματος μου στη συνέχεια το έκανα να ακολουθεί το χέρι.
 ![image](https://user-images.githubusercontent.com/93786079/207907265-199f6c3d-c44a-42c3-b940-bc696c9f7b57.png)

3ο Υποερώτημα:
Μέσω της χρήσης μιας βιβλιοθήκης Computer Vision, όπως της OpenCV for Processing, μας ζητήθηκε να επεξεργαστούμε το έτοιμο παράδειγμα BackgroundSubstraction κατάλληλα ώστε αντί για το υπάρχον βίντεο (street.mov) θα πρέπει να υπάρξει είσοδος από την κάμερα για τον εντοπισμό των κινούμενων αντικειμένων. Αρχικά με τον κατάλληλο κώδικα έκανα πάλι την κάμερα να καταγράφει βίντεο και έπειτα ο εντοπισμός των κινούμενων αντικειμένων έγινε μέσω ενός μπλε highlight γύρω από αυτά.
 ![image](https://user-images.githubusercontent.com/93786079/207907306-ad0ee67d-5943-4315-b122-72b40d6ed5a5.png)

4ο Υποερώτημα:

Αφού επεξεργάστηκα κατάλληλα το Example 16-11 από το βιβλίο Learning Processing, 2nd Edition έκανα την είσοδο του παραδείγματος  να γίνεται από ένα αντικείμενο της επιλογής μου το οποίο είναι ένα τετράγωνο. Όπου κλικάρει ο χρήστης με το ποντίκι του εμφανίζεται μία σειρά από τετράγωνα σε επανάληψη.

![image](https://user-images.githubusercontent.com/93786079/207907332-d700f477-f13e-464b-bd7c-e4fe2e24603b.png)

![image](https://user-images.githubusercontent.com/93786079/207907343-05371a64-7bb5-445a-a53a-b6db68f5c95b.png)

![image](https://user-images.githubusercontent.com/93786079/207907369-c3b6f8bc-f457-4ad3-a778-68bc1489d886.png)

# 3rd Deliverable

 Στο πρώτο υποερώτημα του 3ου παραδοτέου μας ζητήθηκε να κάνουμε εγκατάσταση της εφαρμογής reacTIVision  engine 

1.	Εγκατέστησα τη βιβλιοθήκης reacTIVision στο Processing.

2.	Προσπάθησα να κάνω εγκατάσταση της εφαρμογής TUIO Simulator αλλά δυστυχώς δεν γνωρίζω τον λόγο που δεν κατέβαινε το αρχείο TUIOSimulator.jar από το οποίο θα άνοιγα κανονικά το simulator

3.	Έκανα εκτέλεση του παραδείγματος TUIO demo με τη χρήση του reacTIVision  engine καθώς όπως ανέφερα παραπάνω δεν μπόρεσα να το κάνω μέσω του simulator

Σαν δεύτερο υποερώτημα μας ζητήθηκε να φτιάξουμε μια εφαρμογή επεξεργασίας εικόνας φωτογραφιών (π.χ. μεγέθυνση, μετακίνηση, αντίθεση, φωτεινότητα, κ.α) που θα χρησιμοποιεί την κάμερα για την αναγνώριση και παρακολούθηση των κωδικών fiducials, με βάση το παράδειγμα TUIO demo. Οι κωδικοί fiducials θα αντιπροσωπεύουν δύο φωτογραφίες που εγώ τοποθέτησα και αυτές είναι οι εξής:  

![image](https://user-images.githubusercontent.com/93786079/212409237-c64dcd98-7da9-4ebe-8edf-fd2823fe8f05.png)

image2: pao_2

 ![image](https://user-images.githubusercontent.com/93786079/212409277-f9944a66-10ce-49fe-8c42-ca850771a5c3.png)
 
 image1: pao_1

Έτσι μέσω της εφαρμογής reacTIVision και του processing με τον κατάλληλα διαμορφωμένο κώδικα και απαραίτητες προσθήκες στο παράδειγμα του TuioDemo πέτυχα να έχω αναγνώριση δύο fiducials και έτσι να εμφανίζονται οι παραπάνω εικόνες. Με την αναγνώριση του fiducial 1 με ID 1 εμφανίζεται δίπλα στην οθόνη του processing η image1 και με την αναγνώριση του fiducial 2 εμφανίζεται η image2. 

![image](https://user-images.githubusercontent.com/93786079/212409329-ef7ae88f-cc4a-49d7-b849-acba83bf7461.png)
![image](https://user-images.githubusercontent.com/93786079/212409352-5b2fcb25-783b-4b56-bd68-881a14ef64c1.png)

Δεν μπόρεσα να δουλέψω όπως ανέφερα και παραπάνω με το Tuio Simulator όμως θεωρώ πως η χρήση της εφαρμογής της reacTIVision βολεύει περισσότερο στη φάση της σχεδίασης κατά την οποία θα μας βόλευε να έχουμε 2 οθόνες και άρα θα έχουμε περισσότερο περιεχόμενο να διαχειριστούμε. Η περίπτωση του simulator από ότι έψαξα και βρήκα είναι με μία οθόνη οπότε θα βόλευε καλύτερα για παράδειγμα με μία εικόνα.

# Conclusion
Τελικά συμμπεράσματα προκύπτουν κυρίως σχετικά με την εφαρμογή του processing και τις διάφορες μεθόδους που μπορούν να χρησιμοποιηθούν. Μπορούμε να έχουμε αλληλεπίδραση του χρήστη με διάφορους τρόπους όπως για παράδειγμα να δείξει QR και να εμφανίσει στην οθόνη μία εικόνα ή να στείλει τον χρήστη σε κάποια ιστοσελίδα έπειτα από επεξεργασία της. Μπορεί ακόμα να αλληλεπιδράσει με πολλούς τρόπους με το ποντίκι για παράδειγμα κλικάροντας πάνω στην οθόνη να αλλάζει το background  

# Sources 

Learning Processing, 2nd Edition

https://processing.org/examples/

https://shiffman.net/p5/qrcode-processing/

Διάφορα forum και προφίλ στο GitHubμε με συμβουλευτικό κώδικα τον οποίο προσάρμοζα κατάλλληλα με βάση τις ανάγκες του παραδοτέου
